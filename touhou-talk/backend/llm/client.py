"""
client.py
===========================
LLMï¼ˆå¤–ç•Œï¼‰ã¨ã®é€šä¿¡ã‚’æ‹…å½“ã™ã‚‹å”¯ä¸€ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚

è¨­è¨ˆåŸå‰‡ï¼š
- äººæ ¼OSã¯ LLM ã®å­˜åœ¨ã‚’ä¸€åˆ‡æ„è­˜ã—ãªã„
- OpenAI / ãƒ¢ãƒ‡ãƒ«å / APIã‚­ãƒ¼ / APIä»•æ§˜å·®åˆ†ã¯ã“ã®å±¤ã§å®Œçµ
- å…¥åŠ›ã¯ã€Œmessagesæ§‹é€ ã€ã®ã¿
- å‡ºåŠ›ã¯ã€Œãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã€

.env ä¾å­˜ï¼š
- OPENAI_API_KEY : OpenAI APIã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
- LLM_MODEL      : ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«åï¼ˆä»»æ„ï¼‰

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯
äººæ ¼OSã«ã¨ã£ã¦ã®ã€Œå£°å¸¯ã®å¤–å´ã€ã€Œå¤–ç•Œã¨ã®å–‰ã€ã€‚
"""

from __future__ import annotations

import os
import time
from typing import Dict, Optional, List

# -------------------------------------------------
# .env ã‚’æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã‚€ï¼ˆcmd / PowerShell å¯¾ç­–ï¼‰
# -------------------------------------------------
from dotenv import load_dotenv
load_dotenv()

# -------------------------------------------------
# OpenAI SDK
# -------------------------------------------------
from openai import OpenAI
from openai.types.chat import ChatCompletion


# =================================================
# LLM Client
# =================================================

class LLMClient:
    """
    LLM å‘¼ã³å‡ºã—å°‚ç”¨ã‚¯ãƒ©ã‚¹ã€‚

    äººæ ¼OSå´ã¯ã“ã®ã‚¯ãƒ©ã‚¹ã‚’
    - ã€Œãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ•ã’ã‚‹ç®±ã€
    - ã€Œãƒ†ã‚­ã‚¹ãƒˆãŒè¿”ã‚‹ç®±ã€
    ã¨ã—ã¦ã®ã¿æ‰±ã†ã€‚

    ğŸ‘‰ ãƒ¢ãƒ‡ãƒ«ä»•æ§˜å·®åˆ†ãƒ»APIä»•æ§˜å¤‰æ›´ã¯ã™ã¹ã¦ã“ã“ã§å¸åã™ã‚‹
    """

    def __init__(
        self,
        *,
        model: Optional[str] = None,
        temperature: float = 0.6,
        max_tokens: int = 512,
        timeout_sec: float = 15.0,
        retry: int = 2,
    ) -> None:
        """
        åˆæœŸåŒ–ã€‚

        - APIã‚­ãƒ¼ã¯å¿…ãšç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        - ãƒ¢ãƒ‡ãƒ«åã¯ å¼•æ•° â†’ ç’°å¢ƒå¤‰æ•° â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ ã®é †ã§è§£æ±º
        """

        # -------------------------
        # API Keyï¼ˆå¿…é ˆï¼‰
        # -------------------------
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError(
                "OPENAI_API_KEY is not set. "
                "Please define it in your environment variables or .env file."
            )

        # -------------------------
        # Model nameï¼ˆä»»æ„ï¼‰
        # -------------------------
        # 1. æ˜ç¤ºçš„ã«æ¸¡ã•ã‚ŒãŸ model
        # 2. .env ã® LLM_MODEL
        # 3. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.model = (
            model
            or os.getenv("LLM_MODEL")
            or "gpt-5.1-chat-latest"
        )

        # -------------------------
        # Generation parametersï¼ˆäººæ ¼OSå‘ã‘ï¼‰
        # -------------------------
        # â€» äººæ ¼OSã¯ã€Œtemperature ã‚’æŒ‡å®šã§ãã‚‹ã€å‰æã§è‰¯ã„
        # â€» å®Ÿéš›ã«é€ã‚‹ã‹ã©ã†ã‹ã¯ä¸‹å±¤ã§åˆ¤æ–­ã™ã‚‹
        self.temperature = temperature

        # å†…éƒ¨åã¯ max_tokens ã®ã¾ã¾ä¿æŒ
        # ï¼ˆOpenAI API å´ã§ã¯ max_completion_tokens ã«å¤‰æ›ï¼‰
        self.max_tokens = max_tokens

        self.timeout_sec = timeout_sec
        self.retry = retry

        # -------------------------
        # OpenAI client
        # -------------------------
        # äººæ ¼OSãŒå”¯ä¸€ã€Œå¤–ç•Œã€ã«è§¦ã‚Œã‚‹å ´æ‰€
        self._client = OpenAI(api_key=api_key)

    # =================================================
    # public API
    # =================================================

    def generate(
        self,
        *,
        system: str,
        user: str,
    ) -> str:
        """
        system / user ã‚’å—ã‘å–ã‚Šã€
        LLM ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’è¿”ã™ã€‚

        äººæ ¼OSãŒå‘¼ã¶å”¯ä¸€ã®é–¢æ•°ã€‚
        """

        # -------------------------
        # messages æ§‹é€ ï¼ˆOpenAI æ¨™æº–ï¼‰
        # -------------------------
        messages: List[Dict[str, str]] = [
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ]

        last_error: Optional[Exception] = None

        # -------------------------
        # retry loop
        # -------------------------
        for attempt in range(self.retry + 1):
            try:
                completion = self._call_llm(messages)
                return self._extract_text(completion)

            except Exception as e:
                last_error = e
                # è»½ã„ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆäººæ ¼OSã«æºã‚Œã‚’ä¼æ’­ã•ã›ãªã„ï¼‰
                time.sleep(0.5 * (attempt + 1))

        # å…¨è©¦è¡Œå¤±æ•—æ™‚
        raise RuntimeError("LLM call failed after retries") from last_error

    # =================================================
    # internal
    # =================================================

    def _call_llm(self, messages: List[Dict[str, str]]) -> ChatCompletion:
        """
        å®Ÿéš›ã® LLM å‘¼ã³å‡ºã—ã€‚

        ã“ã“ã§è¡Œã†ã“ã¨ï¼š
        - OpenAI æ–°æ—§ä»•æ§˜å·®åˆ†ã®å¸å
        - ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ã€Œé€ã£ã¦ã¯ã„ã‘ãªã„å¼•æ•°ã€ã®é™¤å¤–

        ğŸ‘‰ äººæ ¼OSã¯ã“ã®äº‹æƒ…ã‚’ä¸€åˆ‡çŸ¥ã‚‰ãªãã¦ã‚ˆã„
        """

        # -------------------------
        # å…±é€šå¼•æ•°ï¼ˆå…¨ãƒ¢ãƒ‡ãƒ«å…±é€šï¼‰
        # -------------------------
        kwargs = {
            "model": self.model,
            "messages": messages,
            # ğŸ”µ æ–°ä»•æ§˜ï¼šmax_tokens â†’ max_completion_tokens
            "max_completion_tokens": self.max_tokens,
            "timeout": self.timeout_sec,
        }

        # -------------------------
        # temperature ã®æ‰±ã„ï¼ˆé‡è¦ï¼‰
        # -------------------------
        # gpt-5.1-chat-latest ç³»ã¯ temperature ã‚’å—ã‘ä»˜ã‘ãªã„
        # â†’ æŒ‡å®šã™ã‚‹ã¨ 400 BadRequest ã«ãªã‚‹
        #
        # å°†æ¥ temperature å¯¾å¿œãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆãŸå ´åˆã®ã¿
        # ã“ã“ã‚’æœ‰åŠ¹åŒ–ã™ã‚Œã°ã‚ˆã„
        #
        # if self.temperature != 1.0:
        #     kwargs["temperature"] = self.temperature

        return self._client.chat.completions.create(**kwargs)

    def _extract_text(self, completion: ChatCompletion) -> str:
        """
        ChatCompletion ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å®‰å…¨ã«æŠ½å‡ºã€‚

        â€» ã“ã“ã§ã¯ä¸€åˆ‡åŠ å·¥ã—ãªã„
           â†’ guard.py / repair.py ã®è²¬å‹™
        """

        if not completion.choices:
            return ""

        message = completion.choices[0].message
        if not message or not message.content:
            return ""

        return message.content.strip()